# AI Worker â€“ Funktions- und Unterfunktionen-Checkliste

Stand: Code-Analyse (Laufzeittests erfordern Python/Umgebung).  
**Legende:** âœ… vermutlich OK (Code konsistent) | âš ï¸ Bedingt / Konfiguration nÃ¶tig | âŒ Fehler/Defizit erkannt | ğŸ”² Laufzeittest nÃ¶tig

---

## 1. Einstieg & Routing (main.py)

| # | Funktion | Beschreibung | Status |
|---|----------|--------------|--------|
| 1.1 | `GET /` | Root â€“ Service-Name, Version, status | âœ… |
| 1.2 | CORS-Middleware | Origins aus `cors_origins` (Env) | âœ… |
| 1.3 | Router: `/health` | Health-Checks | âœ… |
| 1.4 | Router: `/classify` | Klassifikation & Scoring | âœ… |
| 1.5 | Router: `/plan` | Plan-Generierung & Optimize | âœ… |
| 1.6 | Router: `/crawl` | Crawl-Trigger & Status | âœ… |
| 1.7 | Router: `/metrics` | Metriken & Health-Summary | âœ… |

---

## 2. Health (`/health`)

| # | Funktion | Unterfunktion | Status |
|---|----------|----------------|--------|
| 2.1 | `GET /health/` | Basis-Health (immer ok wenn Service lÃ¤uft) | âœ… |
| 2.2 | `GET /health/ready` | Readiness inkl. AbhÃ¤ngigkeiten | âš ï¸ |
| 2.2.1 | | `_check_redis()` â€“ Redis Ping | ğŸ”² Redis-URL nÃ¶tig |
| 2.2.2 | | `_check_backend()` â€“ GET backend_url/api/health | ğŸ”² Backend-URL nÃ¶tig |
| 2.2.3 | | `_check_openai()` â€“ nur wenn openai_api_key gesetzt | ğŸ”² Optional |

**Backend nutzt:** `GET /health` (Admin-Health-Proxy), `GET /health/ready`, `GET /metrics/health-summary` fÃ¼r Dashboard.

---

## 3. Classify (`/classify`)

| # | Funktion | Unterfunktion | Status |
|---|----------|----------------|--------|
| 3.1 | `POST /classify/event` | Event klassifizieren (Familientauglichkeit) | âš ï¸ |
| 3.1.1 | | Rule-Based Pre-Filter (`RuleBasedFilter.check`) | âœ… |
| 3.1.2 | | Bei Regel-Entscheidung: sofort zurÃ¼ck, kein AI | âœ… |
| 3.1.3 | | Sonst: `EventClassifier.classify()` (AI) | ğŸ”² OpenAI/Anthropic-Key nÃ¶tig |
| 3.1.4 | | PII-Redaktion, Schema-Validierung, Retry/Eskalation (im Classifier) | âœ… |
| 3.2 | `POST /classify/score` | Event bewerten (Scores 0â€“100) | âš ï¸ |
| 3.2.1 | | `EventScorer.score()` â€“ relevance, quality, family_fit, stressfree | ğŸ”² API-Key nÃ¶tig |
| 3.2.2 | | Fallback: `_default_scoring` wenn kein Key / AI aus | âœ… |
| 3.3 | `POST /classify/batch` | Mehrere Events nacheinander klassifizieren | âœ… (ruft 3.1 pro Event) |

**Backend nutzt:**  
- `POST /classify/event` und `POST /classify/score` in `process-pending-ai` (Batch-KI)  
- `POST /classify/event` und `POST /classify/score` im Cron `process-pending-ai` (sources.ts)

**MÃ¶gliche Fehlerquellen:**  
- Fehlender `OPENAI_API_KEY` oder `ANTHROPIC_API_KEY` â†’ Classify/Score schlagen fehl oder nutzen Default.  
- `enable_ai: false` â†’ Scorer nutzt Default, Classifier kÃ¶nnte trotzdem AI erwarten (Rule-Filter liefert oft None â†’ AI-Pfad).

---

## 4. Crawl (`/crawl`)

| # | Funktion | Unterfunktion | Status |
|---|----------|----------------|--------|
| 4.1 | `POST /crawl/trigger` | Crawl-Job auslÃ¶sen | âš ï¸ |
| 4.1.1 | | Job in Redis-Queue einreihen (QUEUE_CRAWL) | ğŸ”² Redis nÃ¶tig |
| 4.1.2 | | Fallback: Sync in BackgroundTasks (`run_crawl_sync`) | âœ… |
| 4.2 | `GET /crawl/status/{job_id}` | Job-Status abfragen | ğŸ”² Redis fÃ¼r echte Statusdaten |
| 4.3 | `GET /crawl/queue-stats` | Queue-LÃ¤nge (crawl) | ğŸ”² Redis |
| 4.4 | `POST /crawl/process-feed` | Feed-URL direkt parsen (RSS/ICS), nur Vorschau | âœ… (kein Redis nÃ¶tig) |

**Worker-Pipeline (bei Sync/Queue):**  
`process_crawl_job` â†’ FeedParser â†’ ggf. Deep-Fetch â†’ Normalizer â†’ In-Run-Dedupe â†’ ggf. AI (Classifier+Scorer) â†’ Batch an Backend `POST /api/sources/ingest/batch`.

**MÃ¶gliche Fehlerquellen:**  
- Redis nicht erreichbar: Trigger funktioniert mit Sync-Fallback, aber Status/Queue-Stats unzuverlÃ¤ssig.  
- Backend-URL/Service-Token falsch: Ingest-Batch schlÃ¤gt fehl.  
- Feed-Parser/Deep-Fetch: Fehler bei kaputten Feeds oder Timeouts.

---

## 5. Plan (`/plan`)

| # | Funktion | Unterfunktion | Status |
|---|----------|----------------|--------|
| 5.1 | `POST /plan/generate` | VollstÃ¤ndigen Tagesplan mit AI erzeugen | ğŸ”² API-Key + Events nÃ¶tig |
| 5.1.1 | | `PlanGenerator.generate()` â€“ Wetter, AI-Slots, Plan B | âœ… Code |
| 5.2 | `POST /plan/optimize` | Events fÃ¼r einen Tag auswÃ¤hlen (Scores, Budget, DiversitÃ¤t) | âœ… (rein heuristisch, kein LLM) |
| 5.2.1 | | Scoring aus event.scores (family_fit, stressfree, quality) | âœ… |
| 5.2.2 | | Distanz, Preis, Alterspassung, Kategorie-DiversitÃ¤t | âœ… |
| 5.2.3 | | Plan B = Indoor-Alternativen | âœ… |
| 5.3 | `POST /plan/optimize-route` | Reihenfolge/Routen-Optimierung | âœ… (Platzhalter: Nearest-Neighbor, keine echte Routing-API) |

**Backend nutzt:** `POST /plan/optimize` (backend/src/routes/plan.ts) fÃ¼r KI-Planer.

---

## 6. Metrics (`/metrics`)

| # | Funktion | Unterfunktion | Status |
|---|----------|----------------|--------|
| 6.1 | `GET /metrics` | Queue-Tiefen, DLQ, Budget, Usage (7d) | ğŸ”² Redis + Cost-Tracker |
| 6.2 | `GET /metrics/prometheus` | Prometheus-Format | ğŸ”² |
| 6.3 | `GET /metrics/health-summary` | Kurz-Status (redis, dlq, budget, ai_enabled) | ğŸ”² |

**Hinweis:** Routes sind unter Prefix `/metrics` registriert; Aufruf vom Backend: `GET {AI_WORKER_URL}/metrics/health-summary` (laut admin.ts).

---

## 7. AbhÃ¤ngigkeiten (Module)

| Modul | Verwendung | Status |
|-------|------------|--------|
| **config** | Settings (Env), get_settings() | âœ… |
| **classifiers.event_classifier** | EventClassifier, ClassificationResult | âœ… |
| **scorers.event_scorer** | EventScorer, ScoringResult (inkl. fun_score intern) | âœ… |
| **rules.rule_filter** | RuleBasedFilter â€“ Vorfilter vor AI | âœ… |
| **queue.job_queue** | Redis-Queues, enqueue, get_status, get_queue_length | ğŸ”² Redis |
| **queue.worker** | process_crawl_job, enrich_with_ai, Batch-Ingest an Backend | ğŸ”² |
| **crawlers.feed_parser** | RSS/ICS parsen | âœ… |
| **crawlers.rss_deep_fetch** | Optional Deep-Fetch | âœ… |
| **planner.plan_generator** | generate(), Wetter, AI-PlÃ¤ne | ğŸ”² API-Key |
| **monitoring.ai_cost_tracker** | Budget, Usage | âœ… |
| **lib.pii_redactor** | PII vor AI | âœ… |
| **lib.schema_validator** | validate_classification, validate_scoring, validate_plan | âœ… |

---

## 8. Backend-Integration (Ãœberblick)

| Backend-Endpoint | Ruft AI-Worker auf | Status |
|------------------|--------------------|--------|
| POST /api/admin/process-pending-ai | POST /classify/event, POST /classify/score | ğŸ”² AI_WORKER_URL + API-Keys |
| POST /api/sources/cron/process-pending-ai | POST /classify/event, POST /classify/score | ğŸ”² |
| GET /api/admin/ai-worker/health | GET /health | ğŸ”² |
| GET /api/admin/ai-worker/health/detailed | GET /health, /health/ready, /metrics/health-summary | ğŸ”² |
| GET /api/admin/ai-worker/stats | (eigene DB/Redis, nicht Worker) | â€“ |
| GET /api/admin/ai-worker/queue-stats | GET /crawl/queue-stats | ğŸ”² |
| Crawl-Trigger (Sources) | POST /crawl/trigger | ğŸ”² |
| POST /api/plan/generate (mit use_ai) | POST /plan/optimize | ğŸ”² |

---

## 9. Bekannte Risiken / â€Funktioniert nichtâ€œ

1. **Kein API-Key:**  
   - Classify/Score: Ohne `OPENAI_API_KEY`/`ANTHROPIC_API_KEY` nutzt nur der Scorer Defaults; der Classifier hat keinen Fallback und wirft ggf. oder nutzt leere Keys â†’ **500 oder leere/ungenÃ¼gende Werte**.  
   - Plan Generate: Braucht AI â†’ ohne Key fehleranfÃ¤llig.

2. **AI_WORKER_URL in Produktion:**  
   - Backend (Vercel) muss `AI_WORKER_URL` auf die laufende Worker-Instanz setzen (z.â€¯B. Railway).  
   - Fehlt oder ist falsch â†’ alle Aufrufe (Classify, Score, Health, Crawl, Plan) schlagen fehl.

3. **Redis:**  
   - Crawl-Trigger: Mit Redis Queue + Worker; ohne Redis nur Sync-Fallback (Status/Queue-Stats dann nicht aussagekrÃ¤ftig).  
   - Backend: Eigenes Redis fÃ¼r AI-Job-Status (ai_jobs); unabhÃ¤ngig vom Worker-Redis.

4. **Crawl/Ingest:**  
   - Worker sendet Batch an Backend `POST /api/sources/ingest/batch` mit SERVICE_TOKEN.  
   - Falscher backend_url oder falscher Service-Token â†’ Events kommen nicht in die DB â†’ keine pending_ai.

5. **Port/Konfiguration:**  
   - main.py: Port aus settings (default 5000). start.bat muss dieselbe Umgebung/Port nutzen.

---

## 10. Empfohlene Laufzeittests (zum Abhaken)

- [ ] `GET http://localhost:5000/` â†’ 200, status running  
- [ ] `GET http://localhost:5000/health/` â†’ 200, status ok  
- [ ] `GET http://localhost:5000/health/ready` â†’ 200, checks redis/backend/openai  
- [ ] `POST http://localhost:5000/classify/event` mit minimalem JSON (title, description) â†’ 200 + categories/confidence  
- [ ] `POST http://localhost:5000/classify/score` mit minimalem JSON â†’ 200 + family_fit_score etc.  
- [ ] `POST http://localhost:5000/crawl/trigger` (source_id, source_type) â†’ 200 + job_id  
- [ ] `GET http://localhost:5000/crawl/status/{job_id}` â†’ 200 + status  
- [ ] `POST http://localhost:5000/plan/optimize` mit events=[], children_ages, date, budget â†’ 200 + selected_events  
- [ ] `GET http://localhost:5000/metrics/health-summary` â†’ 200 + status/indicators  

Wenn du willst, kann als NÃ¤chstes eine konkrete Fehlerquelle (z.â€¯B. â€Classify liefert 500â€œ oder â€Crawl startet nichtâ€œ) mit dir Schritt fÃ¼r Schritt eingegrenzt werden.
